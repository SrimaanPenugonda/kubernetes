S63:
eksctl - eks cluster by amazon
kubectl - kubernetes cluster
kubectl – A command line tool for working with Kubernetes clusters.
eksctl – A command line tool for working with EKS clusters that automates many individual tasks.

Who is orchestrator :

WHY Kubernetes? Google product
1.Backed by CNCF
2. Cloud Native Product
2.Architecture
  Master Nodes - where kubernetes installed (Amazon EKS)
  Compute Nodes - where docker installed/container running
3.Kubernetes master components
    API Server - which interacts with all components
        users,UI,scheduler all will talk with API server only
    ETCD - it is a DB
    Scheduler-
9. What process runs on Kubernetes Master Node?
The Kube-api server process runs on the master node and serves to scale the deployment of more instances.
API Server: The API server acts as an entry point for all the REST commands used for controlling the cluster.
Etcd: etcd components, store configuration detail, and wright values. It communicates with the most component to receive commands and work. It also manages network rules and port forwarding activity.
Scheduler: The scheduler schedules the tasks to the slave node. It stores the resource usage information for every slave node. It is responsible for distributing the workload.
Kubelet: It gets the configuration of a Pod from the API server and ensures that the described containers are up and running.
Pods: A pod is a combination of single or multiple containers that logically run together on nodes.

kubectl cluster-info
kubectl get nodes
kubectl get nodes -o wide
kubectl api-versions
cat .kube/config
kubernetes uses authorization than authentication - with some key

POD - Kubernetes deals with POD -
 A pod is a combination of single or multiple containers that logically run together on nodes.
POD should have at least contain one container in it
containers in POD can share same storage
containers in POD will use same network stack

create pod:
kubectl run sample --image=nginx (imperative cmd)
we always prefer declarative method so yaml file
apiversion: v1
kind: pod
metadata:
  name: sample1
spec:  -- up ti this 4 will be common for all pods
  containers:
    - name: nginx
      image: nginx

now execute this ..kubectl apply -f 01-pod.yml
kubectl get pods
display both sample and sample1
metadata:
  name: sample2
spec:
  containers:
    - name: nginx
      image: nginx
    - name: centos
      image: centos:7
      command: ["sleep","20"]

sample2 pod will have 2 containers
pass the config to POD
    -using env variables
    env:
    - name: URL
      value: google.com
k9s: Kubernetes CLI To Manage Your Clusters In Style
ctrl+k will kill the pod
s- will into the pod
select the container
env- display all env variables
env file - configmaps
03-configmaps.yml
    careful about case sensitive.. apiVersion
    Pod should be like this
secret-
kind: Secret
data:
 URL: "" // give base64 format

-secretRef:
    name:

Health Checks:
    - name: health
      image: srimaanaws2021/healthcheck
      livenessProbe:
        exec:
          command:
            - cat
            - /opt/file.txt
        initialDelaySeconds: 5
        periodSeconds: 5
s64:
RESOURCES:
resources support min and max which is called requests and limits
requests - where min will be specified
limits - where max values specified

PVC: persistent volume claim:
Containers are Ephemeral
we need to deal with storing the data from container and we should not be lost even if pod/container
is terminated
can be achieved by attaching storage
Storage can be deal in kubernetes by PersistentVolume (-v path in docker)
PersistentVolume claim/storage class
PV - large unit provided by administrators

kind: PersistentVolumeClaim
metadata:
    name: mysql
spec:
acessmodes: Readwriteonce
kubectl get storageclass - get the storage class name - gp2

spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 1Gi
  storageClassName: gp2

kubectl apply -f 07-pvc.yml
pvc has reserved

pvc has to mount to a pod
add pod now
---
apiVersion: v1
kind: Pod
metadata:
  name: mysql
spec:
  containers:
    - name: mysql
      image: mysql
      env:
        - name: MYSQL_ROOT_PWD
          value: root123
      volumeMounts:
      - mountPath: "/var/lib/mysql"
        name: mysql
  volumes:
    - name: mysql
      persistentVolumeClaim:
        claimName: mysql   #pvc name
this pod is created with pvc mysql
if we kill the pod and attached this pvc to another new pod  data will be persitant

Sets in PODS:
we don't configure pods directly in kubernetes bz it cant be scalable
kubernetes offers sets
ReplicaSet,statefulSet,DaemonSet
Enhancing to ReplicaSet Deployment

ReplicaSet:
kind: ReplicaSet
metadata:
  name: nginx
  labels:
    tier: nginx
labels has to be there
  replicas: 1 it will launch number of pods
  spec:
    replicas: 1
    selector:
      matchLabels:
        tier: nginx
    template:
      metadata:
        labels:
          tier: nginx  -- this is the spec for replica
  spec:
        containers:
          - name: nginx
            image: nginx:1.16 - this is spec for container
     if we change the container spec.. and run this set
     existing pod wont modify
we need to modify the existing pod, pod refresh.. like instance refresh in asg
this can be handle by Deployment
kubectl get rs - pull the replicaSets
NAME    DESIRED   CURRENT   READY   AGE
nginx   2         2         2       98s
if any f the pod killed immediate another one launches

Deployment:
kind: Deployment - only change
now if we change the container spec.. automatically new pod will create with new
spec and exiting one will terminate

kubectl scale deploy nginx --replicas=2 -
we can scale this deployment set using this cmd

services in kubernetes :
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec:
  selector:
    tier: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80

loadbalacer:
type: LoadBalancer


