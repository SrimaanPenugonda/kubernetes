S63:
eksctl - eks cluster by amazon
kubectl - kubernetes cluster
kubectl – A command line tool for working with Kubernetes clusters.
eksctl – A command line tool for working with EKS clusters that automates many individual tasks.

Who is orchestrator :

WHY Kubernetes? Google product
1.Backed by CNCF
2. Cloud Native Product
2.Architecture
  Master Nodes - where kubernetes installed (Amazon EKS)
  Compute Nodes - where docker installed/container running
3.Kubernetes master components
    API Server - which interacts with all components
        users,UI,scheduler all will talk with API server only
    ETCD - it is a DB
    Scheduler-
9. What process runs on Kubernetes Master Node?
The Kube-api server process runs on the master node and serves to scale the deployment of more instances.
API Server: The API server acts as an entry point for all the REST commands used for controlling the cluster.
Etcd: etcd components, store configuration detail, and wright values. It communicates with the most component to receive commands and work. It also manages network rules and port forwarding activity.
Scheduler: The scheduler schedules the tasks to the slave node. It stores the resource usage information for every slave node. It is responsible for distributing the workload.
Kubelet: It gets the configuration of a Pod from the API server and ensures that the described containers are up and running.
Pods: A pod is a combination of single or multiple containers that logically run together on nodes.

kubectl cluster-info
kubectl get nodes
kubectl get nodes -o wide
kubectl api-versions
cat .kube/config
kubernetes uses authorization than authentication - with some key

POD - Kubernetes deals with POD -
 A pod is a combination of single or multiple containers that logically run together on nodes.
POD should have at least contain one container in it
containers in POD can share same storage
containers in POD will use same network stack

create pod:
kubectl run sample --image=nginx (imperative cmd)
we always prefer declarative method so yaml file
apiversion: v1
kind: pod
metadata:
  name: sample1
spec:  -- up ti this 4 will be common for all pods
  containers:
    - name: nginx
      image: nginx

now execute this ..kubectl apply -f 01-pod.yml
kubectl get pods
display both sample and sample1
metadata:
  name: sample2
spec:
  containers:
    - name: nginx
      image: nginx
    - name: centos
      image: centos:7
      command: ["sleep","20"]

sample2 pod will have 2 containers
pass the config to POD
    -using env variables
    env:
    - name: URL
      value: google.com
k9s: Kubernetes CLI To Manage Your Clusters In Style
ctrl+k will kill the pod
s- will into the pod
select the container
env- display all env variables
env file - configmaps
03-configmaps.yml
    careful about case sensitive.. apiVersion
    Pod should be like this
secret-
kind: Secret
data:
 URL: "" // give base64 format

-secretRef:
    name:

Health Checks:
    - name: health
      image: srimaanaws2021/healthcheck
      livenessProbe:
        exec:
          command:
            - cat
            - /opt/file.txt
        initialDelaySeconds: 5
        periodSeconds: 5
s64:
RESOURCES:
resources support min and max which is called requests and limits
requests - where min will be specified
limits - where max values specified

PVC: persistent volume claim:
Containers are Ephemeral
we need to deal with storing the data from container and we should not be lost even if pod/container
is terminated
can be achieved by attaching storage
Storage can be deal in kubernetes by PersistentVolume (-v path in docker)
PersistentVolume claim/storage class
PV - large unit provided by administrators

kind: PersistentVolumeClaim
metadata:
    name: mysql
spec:
acessmodes: Readwriteonce
kubectl get storageclass - get the storage class name - gp2

spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 1Gi
  storageClassName: gp2

kubectl apply -f 07-pvc.yml
pvc has reserved

pvc has to mount to a pod
add pod now
---
apiVersion: v1
kind: Pod
metadata:
  name: mysql
spec:
  containers:
    - name: mysql
      image: mysql
      env:
        - name: MYSQL_ROOT_PWD
          value: root123
      volumeMounts:
      - mountPath: "/var/lib/mysql"
        name: mysql
  volumes:
    - name: mysql
      persistentVolumeClaim:
        claimName: mysql   #pvc name
this pod is created with pvc mysql
if we kill the pod and attached this pvc to another new pod  data will be persitant

Sets in PODS:
we don't configure pods directly in kubernetes bz it cant be scalable
kubernetes offers sets
ReplicaSet,statefulSet,DaemonSet
Enhancing to ReplicaSet Deployment

ReplicaSet:
kind: ReplicaSet
metadata:
  name: nginx
  labels:
    tier: nginx
labels has to be there
  replicas: 1 it will launch number of pods
  spec:
    replicas: 1
    selector:
      matchLabels:
        tier: nginx
    template:
      metadata:
        labels:
          tier: nginx  -- this is the spec for replica
  spec:
        containers:
          - name: nginx
            image: nginx:1.16 - this is spec for container
     if we change the container spec.. and run this set
     existing pod wont modify
we need to modify the existing pod, pod refresh.. like instance refresh in asg
this can be handle by Deployment
kubectl get rs - pull the replicaSets
NAME    DESIRED   CURRENT   READY   AGE
nginx   2         2         2       98s
if any f the pod killed immediate another one launches

Deployment:
kind: Deployment - only change
now if we change the container spec.. automatically new pod will create with new
spec and exiting one will terminate

kubectl scale deploy nginx --replicas=2 -
we can scale this deployment set using this cmd

services in kubernetes :
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec:
  selector:
    tier: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80

loadbalacer:
type: LoadBalancer

S65:
Helm Charts are simply Kubernetes YAML manifests combined into a single package that can be advertised to your Kubernetes clusters.
Improves productivity
Reduces the complexity of deployments of microservices
Enables the adaptation of cloud native applications

mysql 5.7 kubernetes helmchart
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install mysql bitnami/mysql --set image.tag=5.7.26
svc attached
:svc inn k9s go to svc's
mysql-headless is the svc service

kubectl get secrets
kubectl get secrets mysql -o yaml
mysql-root-password -
echo pwd |base64 --decode ;echo

helm repo add stable https://charts.helm.sh/stable
helm install mysql  stable/mysql
kubectl get secret --namespace default mysql -o jsonpath="{.data.mysql-root-password}" | base64 --decode;echo
2Ruio0IcUx
mongodb helm chart:
helm install mongodb bitnami/mongodb --set auth.enabled=false
--install mongo without auth

rabbitmq helm chart:
helm install rabbitmq bitnami/rabbitmq
shell -
# rabbitmqctl add_user roboshop roboshop123
# rabbitmqctl set_user_tags roboshop administrator
# rabbitmqctl set_permissions -p / roboshop ".*" ".*" ".*"

redis helm chart:
helm install redis bitnami/redis --set tls.authClients=false

helm install redis stable/redis --set usePassword=false - prefer this

kubectl run debug --image=centos:7 -- sleep 10000
install client
shell
yum install mysql -y
mysql -h mysql -u root -ppwd
download the db and load the schema for both mongodb and mysql
mongo --host mongodbt <users.js - give hostname which we crated above

RELEASE_ARTIFACTS_APP_BUILDID- where our dockerhub repo number will be there

helm ls
helm delete mongodb

eksctl create cluster --name ekstest --region us-east-1 --managed
it will create a VPC and cloudformation stack as well

S67:
Install Prometheus :
helm install prometheus prometheus-community/kube-prometheus-stack
and in Grafana svc change it to LoadBalancer

go to DNS name of load balancer

username/pwd
kubectl get secrets
on k9s :secrets
:pods - show pods
:svc - show services:
:deployment - show deployments
:secrets : show secrets
go to grafana and view yaml file by pressing y

echo cHJvbS1vcGVyYXRvcg== |base64 --decode;echo
prom-operator

prometheus also load balancer:
kubectl get ns - to get namespaces- namespaces to isolate the resources
rate(containers_cpu_system_seconds_total{namespace="default",pod=~"shipping.*",image=~"srimaanaws2021.*"}[5m])
~ is like
sun by (pod)(rate(container_cpu_system_seconds_total{namespace="default",pod=~"shipping.*"|~"payment.*",
image=~"srimaanaws2021.*"}[5m]))

S68:
ELK - Kibana
filebeat collect logs

add helm repo elastic
helm install filebeat elastic/filebeat
filebeat is daemon set - pods will create as number of nodes
:configmap
go to filebeat - we can see output sending to elasticsearch..
output.elasticsearch -
hosts
change it to
output.logstash
hosts:'ELKip:5044'
telnet elkip 5044.. to check the connection
got ELK box:
cd /etc/logstash/conf.d -

  index => "%{[kubernetes][container][name]}-%{+yyyy.MM.dd}" -update this in logstash.conf file
  update [fields][app] with above at all places





